{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31d8522e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2717ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f157b16",
   "metadata": {},
   "source": [
    "### Initializing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda9120d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eae15ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"openai/gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89916a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 7473\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d37f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hun = ds['train'][:100]\n",
    "test_hun = ds['test'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee2e2243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hun['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e476ffea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hun['answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cecb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyAAKQ86BBC85L5RY3r2NWIlcl6_rwsVJ9k'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_api = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f9d7adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.\\n#### 72'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_hun['answer'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_google_llm(google_model = \"gemini-2.5-flash\", query):\n",
    "    basic_prompt_file = \"prompt_templates/basic_p.txt\"\n",
    "    with open(basic_prompt_file, 'r') as file:\n",
    "        BASIC_PROMPT = file.read()\n",
    "    \n",
    "    prompt_template = PromptTemplate.from_template(BASIC_PROMPT)\n",
    "    prompt_template.invoke({\"question\": query})\n",
    "\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model = google_model,\n",
    "        temperature = 0,\n",
    "        timeout = None,\n",
    "        max_retried=1,\n",
    "    )\n",
    "    chain = prompt_template | llm\n",
    "    response = chain.invoke({})\n",
    "    print(response.content)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84889cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gsm8k(llm):\n",
    "    ds = load_dataset(\"openai/gsm8k\", \"main\")\n",
    "    test_hud = ds['test'][:100]\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
